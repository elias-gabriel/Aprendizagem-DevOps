{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install azure-mgmt-datafactory\n",
    "#pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import ClientSecretCredential\n",
    "from azure.mgmt.datafactory import DataFactoryManagementClient\n",
    "from azure.mgmt.datafactory.models import RunFilterParameters\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = ''\n",
    "client_id = ''\n",
    "client_secret = ''\n",
    "tenant_id = ''\n",
    "resource_group_name = ''\n",
    "data_factory_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = ClientSecretCredential(client_id=client_id, client_secret=client_secret, tenant_id=tenant_id)\n",
    "adf_client = DataFactoryManagementClient(credentials, subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate(subscription_id, client_id, client_secret, tenant_id):\n",
    "    credentials = ClientSecretCredential(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        tenant_id=tenant_id\n",
    "    )\n",
    "    return DataFactoryManagementClient(credentials, subscription_id)\n",
    "\n",
    "def list_pipelines(adf_client, resource_group_name, data_factory_name):\n",
    "    pipelines = adf_client.pipelines.list_by_factory(resource_group_name, data_factory_name)\n",
    "    for pipeline in pipelines:\n",
    "        print(f\"Pipeline: {pipeline.name}\")\n",
    "\n",
    "def list_datasets(adf_client, resource_group_name, data_factory_name):\n",
    "    datasets = adf_client.datasets.list_by_factory(resource_group_name, data_factory_name)\n",
    "    for dataset in datasets:\n",
    "        print(f\"Dataset: {dataset.name}\")\n",
    "\n",
    "def list_linked_services(adf_client, resource_group_name, data_factory_name):\n",
    "    linked_services = adf_client.linked_services.list_by_factory(resource_group_name, data_factory_name)\n",
    "    for linked_service in linked_services:\n",
    "        print(f\"Linked Service: {linked_service.name}\")\n",
    "\n",
    "def list_triggers(adf_client, resource_group_name, data_factory_name):\n",
    "    triggers = adf_client.triggers.list_by_factory(resource_group_name, data_factory_name)\n",
    "    if triggers:\n",
    "        for trigger in triggers:\n",
    "            print(f\"Trigger: {trigger.name}\")\n",
    "    else:\n",
    "        print(\"Nenhum trigger encontrado\")\n",
    "\n",
    "def list_last_pipeline_runs(adf_client, resource_group_name, data_factory_name, retantion_days):\n",
    "    pipeline_runs = adf_client.pipeline_runs.query_by_factory(\n",
    "        resource_group_name,\n",
    "        data_factory_name,\n",
    "        filter_parameters=RunFilterParameters(\n",
    "            last_updated_after=datetime.utcnow() - timedelta(days=retantion_days),\n",
    "            last_updated_before=datetime.utcnow()\n",
    "        )\n",
    "    )\n",
    "    for run in pipeline_runs.value:\n",
    "        start_time = run.run_start.strftime(\"%Y-%m-%d %H:%M:%S\") if run.run_start else \"N/A\"\n",
    "        end_time = run.run_end.strftime(\"%Y-%m-%d %H:%M:%S\") if run.run_end else \"N/A\"\n",
    "        print(f\"Pipeline '{run.pipeline_name}': Run ID {run.run_id} - Status: {run.status}, Start: {start_time}, End: {end_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pipelines ===\n",
      "Pipeline: pipe_copydata\n",
      "Pipeline: pipe_lookup\n",
      "Pipeline: pipe_getmetadata\n",
      "Pipeline: pipe_storedprocedures\n",
      "Pipeline: pipe_wait\n",
      "Pipeline: pipe_filter\n",
      "Pipeline: pipe_foreach\n",
      "Pipeline: pipe_parametros\n",
      "Pipeline: pipe_execpipe\n",
      "Pipeline: pratica_01\n",
      "Pipeline: pratica_03\n",
      "Pipeline: pratica_02\n",
      "Pipeline: pratica_04\n",
      "Pipeline: pipeline1\n",
      "Pipeline: page_to_blob\n",
      "\n",
      "=== Datasets ===\n",
      "Dataset: ds_json_fixo\n",
      "Dataset: ds_fixo_asql\n",
      "Dataset: ds_excel_fixo\n",
      "Dataset: ds_generico_asql\n",
      "Dataset: ds_generico_csv\n",
      "Dataset: Json1\n",
      "Dataset: ds_generico_parquet\n",
      "Dataset: ds_gen_source\n",
      "Dataset: ds_gen_sink\n",
      "\n",
      "=== Linked Services ===\n",
      "Linked Service: lsdatalake\n",
      "Linked Service: lsasql\n",
      "\n",
      "=== Triggers ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Datetime with no tzinfo will be considered UTC.\n",
      "Datetime with no tzinfo will be considered UTC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Últimas Execuções dos Pipelines ===\n",
      "Pipeline 'pipeline1': Run ID 9d916168-b9d9-4d6e-98f0-4bb976d813f0 - Status: Succeeded, Start: 2024-04-04 15:38:19, End: 2024-04-04 15:38:23\n",
      "Pipeline 'pipeline1': Run ID 1d23dfd2-3a5e-40b5-bcfd-371c8105c9aa - Status: Succeeded, Start: 2024-04-04 15:38:49, End: 2024-04-04 15:38:51\n",
      "Pipeline 'pipeline1': Run ID 406cfb25-e079-4483-9cab-ce49009905b1 - Status: Succeeded, Start: 2024-04-04 15:41:19, End: 2024-04-04 15:41:22\n",
      "Pipeline 'pipeline1': Run ID 3db80eed-9a90-4a5c-a981-1e9c1e469f62 - Status: Succeeded, Start: 2024-04-04 15:43:18, End: 2024-04-04 15:43:20\n",
      "Pipeline 'pipeline1': Run ID 72251613-dd7b-49ae-a97b-869e97d61fd9 - Status: Succeeded, Start: 2024-04-04 15:44:07, End: 2024-04-04 15:44:10\n",
      "Pipeline 'pipeline1': Run ID 13a9ab02-307c-4ea6-9820-2fe15698916b - Status: Succeeded, Start: 2024-04-04 15:44:58, End: 2024-04-04 15:45:01\n",
      "Pipeline 'pipeline1': Run ID 984186b2-7d0c-45ce-be57-43aa90e51c25 - Status: Succeeded, Start: 2024-04-04 15:46:00, End: 2024-04-04 15:46:03\n",
      "Pipeline 'pipeline1': Run ID f49ddf55-04f4-43de-ba60-921b66584964 - Status: Cancelled, Start: 2024-04-04 15:48:05, End: 2024-04-04 15:48:47\n",
      "Pipeline 'pipeline1': Run ID 92265e41-f093-4f4f-94f8-2ef148497a19 - Status: Cancelled, Start: 2024-04-04 16:20:39, End: 2024-04-04 16:21:45\n",
      "Pipeline 'pipeline1': Run ID 7405ccbf-804c-448d-83c8-60538e1c7023 - Status: Cancelled, Start: 2024-04-04 17:27:54, End: 2024-04-04 17:28:46\n"
     ]
    }
   ],
   "source": [
    "# Executando as funções definidas\n",
    "retantion_days = 20\n",
    "\n",
    "print(\"=== Pipelines ===\")\n",
    "list_pipelines(adf_client, resource_group_name, data_factory_name)\n",
    "\n",
    "print(\"\\n=== Datasets ===\")\n",
    "list_datasets(adf_client, resource_group_name, data_factory_name)\n",
    "\n",
    "print(\"\\n=== Linked Services ===\")\n",
    "list_linked_services(adf_client, resource_group_name, data_factory_name)\n",
    "\n",
    "print(\"\\n=== Triggers ===\")\n",
    "list_triggers(adf_client, resource_group_name, data_factory_name)\n",
    "\n",
    "print(\"\\n=== Últimas Execuções dos Pipelines ===\")\n",
    "list_last_pipeline_runs(adf_client, resource_group_name, data_factory_name, retantion_days)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
